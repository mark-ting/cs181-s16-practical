{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "# df_train = pd.read_csv(\"train.csv\")\n",
    "# df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "dftrain1 = pd.read_csv(\"train.csv\")\n",
    "\n",
    "dftest1 = pd.read_csv(\"test.csv\")\n",
    "dftrain1 = dftrain1.drop(['smiles'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfgap = dftrain1['gap']\n",
    "dftrain1 = dftrain1.drop(['gap'], axis = 1)\n",
    "# dftest1 = dftest1.drop(['smiles'], axis = 1)\n",
    "# dftest1 = dftest1.drop(['Id'], axis = 1)\n",
    "sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "dftrain1 = pd.DataFrame(sel.fit_transform(dftrain1))\n",
    "# dftest1 = pd.DataFrame(sel.fit_transform(dftest1))\n",
    "desired_features = sel.get_support(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_001',\n",
       " 'feat_006',\n",
       " 'feat_025',\n",
       " 'feat_037',\n",
       " 'feat_068',\n",
       " 'feat_069',\n",
       " 'feat_072',\n",
       " 'feat_087',\n",
       " 'feat_090',\n",
       " 'feat_102',\n",
       " 'feat_119',\n",
       " 'feat_123',\n",
       " 'feat_173',\n",
       " 'feat_187',\n",
       " 'feat_218',\n",
       " 'feat_225',\n",
       " 'feat_243',\n",
       " 'feat_251']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdesired_features=[]\n",
    "for elem in list(desired_features+1):\n",
    "    if elem<10:\n",
    "        newElem=\"feat_00\"+str(elem)\n",
    "    elif elem<100:\n",
    "        newElem=\"feat_0\"+str(elem)\n",
    "    else:\n",
    "        newElem=\"feat_\"+str(elem)\n",
    "    newdesired_features.append(newElem)\n",
    "    \n",
    "newdesired_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftrain1.columns=newdesired_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_025</th>\n",
       "      <th>feat_037</th>\n",
       "      <th>feat_068</th>\n",
       "      <th>feat_069</th>\n",
       "      <th>feat_072</th>\n",
       "      <th>feat_087</th>\n",
       "      <th>feat_090</th>\n",
       "      <th>feat_102</th>\n",
       "      <th>feat_119</th>\n",
       "      <th>feat_123</th>\n",
       "      <th>feat_173</th>\n",
       "      <th>feat_187</th>\n",
       "      <th>feat_218</th>\n",
       "      <th>feat_225</th>\n",
       "      <th>feat_243</th>\n",
       "      <th>feat_251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_001  feat_006  feat_025  feat_037  feat_068  feat_069  feat_072  \\\n",
       "0         0         0         0         0         1         0         1   \n",
       "1         1         0         1         1         0         1         1   \n",
       "2         1         1         0         1         1         1         1   \n",
       "3         1         1         1         0         1         0         0   \n",
       "4         0         0         0         0         0         0         1   \n",
       "\n",
       "   feat_087  feat_090  feat_102  feat_119  feat_123  feat_173  feat_187  \\\n",
       "0         0         1         0         1         0         0         0   \n",
       "1         0         1         1         0         0         1         1   \n",
       "2         1         1         0         1         1         1         0   \n",
       "3         1         1         1         0         1         1         0   \n",
       "4         0         1         0         1         0         0         0   \n",
       "\n",
       "   feat_218  feat_225  feat_243  feat_251  \n",
       "0         0         0         0         0  \n",
       "1         1         0         0         1  \n",
       "2         0         0         1         0  \n",
       "3         1         0         1         0  \n",
       "4         0         0         0         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predesired_features=newdesired_features\n",
    "# predesired_features.append('gap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dftrain1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_001',\n",
       " 'feat_006',\n",
       " 'feat_025',\n",
       " 'feat_037',\n",
       " 'feat_068',\n",
       " 'feat_069',\n",
       " 'feat_072',\n",
       " 'feat_087',\n",
       " 'feat_090',\n",
       " 'feat_102',\n",
       " 'feat_119',\n",
       " 'feat_123',\n",
       " 'feat_173',\n",
       " 'feat_187',\n",
       " 'feat_218',\n",
       " 'feat_225',\n",
       " 'feat_243',\n",
       " 'feat_251']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dftrain1['feat_251']\n",
    "predesired_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cols = dftrain1.columns\n",
    "# colnames = []\n",
    "# for i in xrange(0, len(cols)):\n",
    "#     colnames.append('feat_' + str(i + 1).zfill(3))\n",
    "# dftrain1.columns = colnames\n",
    "# dftrain1=dftrain1[predesired_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # simple model\n",
    "# xvarssimple=list(dftrain1.columns)[0:len(list(dftrain1.columns))-1]\n",
    "# formulasimple = str(\"gap ~ \") + str(xvarssimple[0])\n",
    "# count = 0\n",
    "# for xvar in xvarssimple:\n",
    "#     if count > 0:\n",
    "#         formulasimple = formulasimple + \"+\" + str(xvar)\n",
    "#     count = count + 1\n",
    "\n",
    "# print formulasimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gap ~ feat_001+feat_006+feat_025+feat_037+feat_068+feat_069+feat_072+feat_087+feat_090+feat_102+feat_119+feat_123+feat_173+feat_187+feat_218+feat_225+feat_243+feat_251\n"
     ]
    }
   ],
   "source": [
    "# simple model\n",
    "# xvarssimple=list(dftrain1.columns)[0:len(list(dftrain1.columns))-1]\n",
    "formulasimple = str(\"gap ~ \") + str(predesired_features[0])\n",
    "count = 0\n",
    "for xvar in predesired_features:\n",
    "    if count > 0:\n",
    "        formulasimple = formulasimple + \"+\" + str(xvar)\n",
    "    count = count + 1\n",
    "\n",
    "print formulasimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remainingidsweek[\"0\"]\n",
    "dftrain1['gap'] = dfgap\n",
    "dftrain1['id']=list(dftrain1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_025</th>\n",
       "      <th>feat_037</th>\n",
       "      <th>feat_068</th>\n",
       "      <th>feat_069</th>\n",
       "      <th>feat_072</th>\n",
       "      <th>feat_087</th>\n",
       "      <th>feat_090</th>\n",
       "      <th>feat_102</th>\n",
       "      <th>feat_119</th>\n",
       "      <th>feat_123</th>\n",
       "      <th>feat_173</th>\n",
       "      <th>feat_187</th>\n",
       "      <th>feat_218</th>\n",
       "      <th>feat_225</th>\n",
       "      <th>feat_243</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>gap</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_001  feat_006  feat_025  feat_037  feat_068  feat_069  feat_072  \\\n",
       "0         0         0         0         0         1         0         1   \n",
       "1         1         0         1         1         0         1         1   \n",
       "2         1         1         0         1         1         1         1   \n",
       "3         1         1         1         0         1         0         0   \n",
       "4         0         0         0         0         0         0         1   \n",
       "\n",
       "   feat_087  feat_090  feat_102  feat_119  feat_123  feat_173  feat_187  \\\n",
       "0         0         1         0         1         0         0         0   \n",
       "1         0         1         1         0         0         1         1   \n",
       "2         1         1         0         1         1         1         0   \n",
       "3         1         1         1         0         1         1         0   \n",
       "4         0         1         0         1         0         0         0   \n",
       "\n",
       "   feat_218  feat_225  feat_243  feat_251   gap  id  \n",
       "0         0         0         0         0  1.19   0  \n",
       "1         1         0         0         1  1.60   1  \n",
       "2         0         0         1         0  1.49   2  \n",
       "3         1         0         1         0  1.36   3  \n",
       "4         0         0         0         0  1.98   4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm, ols\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import patsy\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize_ridge(X, y, n_folds=8):\n",
    "    clf = Ridge()\n",
    "    parameters = {\"alpha\":  [1e-2,1e-1 ,1.0,10,100]}\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=\"mean_squared_error\")\n",
    "    gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize_lasso(X, y, n_folds=8):\n",
    "    clf = Lasso()\n",
    "    parameters = {\"alpha\":  [1e-6,1e-5 ,1e-4, 1e-3, 1e-2]}\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=\"mean_squared_error\")\n",
    "    gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize_enet(X, y, n_folds=8):\n",
    "    clf=ElasticNet()\n",
    "    parameters = {\"alpha\":  [1e-6,1e-5 ,1e-4, 1e-3, 1e-2]}\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=\"mean_squared_error\")\n",
    "    gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predesired_featuresgap=copy.deepcopy(predesired_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predesired_featuresgap.append('gap')\n",
    "predesired_featuresgap.append('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remainingidsweek.head()\n",
    "# 800000\n",
    "# predesired_featuresgap.append('id')\n",
    "lenTrain=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftrain=dftrain1[predesired_featuresgap][:lenTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "######## Rerunning will overwrite reproducible results\n",
    "\n",
    "# # sample by game ID number to avoid any indexing issues\n",
    "# # store samples (like choosing a seed)\n",
    "\n",
    "\n",
    "\n",
    "uniqueids = dftrain.id\n",
    "traininglength = lenTrain*0.8\n",
    "testinglength = lenTrain*0.1\n",
    "validatelength = lenTrain*0.1\n",
    "\n",
    "testids = np.random.choice(a = uniqueids, size = testinglength, replace = False)\n",
    "remainingids = list([x for x in uniqueids if x not in testids])\n",
    "\n",
    "trainidsdftrain = pd.DataFrame()\n",
    "testidsdf = pd.DataFrame()\n",
    "remainingidsdf = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    trainidsdftrain[i] = np.random.choice(a = remainingids, size = traininglength, replace = False)\n",
    "testidsdf[0] = testids\n",
    "remainingidsdf[0] = remainingids\n",
    "\n",
    "trainidsdftrain.to_csv(\"trainidsdftrain.csv\")\n",
    "testidsdf.to_csv(\"testidsdf.csv\")\n",
    "remainingidsdf.to_csv(\"remainingidsdf.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squarelist(list):\n",
    "    return [ x**2 for x in list ]\n",
    "\n",
    "def abslist(list):\n",
    "    return [ abs(x) for x in list ]\n",
    "\n",
    "def rootlist(list):\n",
    "    return [ np.sqrt(x) for x in list ]\n",
    "\n",
    "# sources: http://stackoverflow.com/questions/12555443/squaring-all-elements-in-a-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.98 s, sys: 102 ms, total: 4.08 s\n",
      "Wall time: 4.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takehiro/anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:444: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "# Stats for the Simple Model\n",
    "olsmsessimple = []\n",
    "olsmadssimple = []\n",
    "ridgemsessimple = []\n",
    "ridgemadssimple = []\n",
    "lassomsessimple = []\n",
    "lassomadssimple = []\n",
    "enetmsessimple = []\n",
    "enetmadssimple = []\n",
    "\n",
    "# Stats for the Intuitive Model\n",
    "olsmsesintuitive = []\n",
    "olsmadsintuitive = []\n",
    "ridgemsesintuitive = []\n",
    "ridgemadsintuitive = []\n",
    "lassomsesintuitive = []\n",
    "lassomadsintuitive = []\n",
    "enetmsesintuitive = []\n",
    "enetmadsintuitive = []\n",
    "\n",
    "# Stats for the Full Model\n",
    "olsmsesall = []\n",
    "olsmadsall = []\n",
    "ridgemsesall = []\n",
    "ridgemadsall = []\n",
    "lassomsesall = []\n",
    "lassomadsall = []\n",
    "enetmsesall = []\n",
    "enetmadsall = []\n",
    "\n",
    "coeffsLinear=[]\n",
    "coeffsRidge=[]\n",
    "coeffsLasso=[]\n",
    "coeffsEnet=[]\n",
    "\n",
    "\n",
    "# Cross-Validate\n",
    "for i in trainidsdftrain.columns.values:\n",
    "    trainids = trainidsdftrain[i]\n",
    "    validationids = set(remainingids) - set(trainids)\n",
    "    \n",
    "    traindf = dftrain.loc[dftrain[\"id\"].isin(trainids)]\n",
    "    validatedf = dftrain.loc[dftrain[\"id\"].isin(validationids)]\n",
    "    \n",
    "    # make simple model x and y dataframes\n",
    "    forfitsimple = pd.DataFrame(traindf.gap)\n",
    "    forpredsimple = pd.DataFrame(validatedf.gap)\n",
    "    for xvar in predesired_features:\n",
    "        forpredsimple[xvar] = validatedf[xvar]\n",
    "        forfitsimple[xvar] = traindf[xvar]\n",
    "    ytrainsimple,xtrainsimple = patsy.dmatrices(formulasimple, data=forfitsimple)\n",
    "    yvalidatesimple,xvalidatesimple = patsy.dmatrices(formulasimple, data=forpredsimple)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# Simple Models    \n",
    "\n",
    "    # linear\n",
    "    fit = ols(formulasimple, data = forfitsimple).fit()\n",
    "    predsLinear = fit.predict(forpredsimple)\n",
    "    prederrors = []\n",
    "    count = 0\n",
    "    for act in yvalidatesimple:\n",
    "        prederrors.append(float(predsLinear[count] - float(act)))\n",
    "        count = count + 1\n",
    "    \n",
    "    olsmsessimple.append(np.mean(squarelist(prederrors)))\n",
    "    olsmadssimple.append(np.mean(abslist(prederrors))) \n",
    "    coeffsLinear.append(fit)\n",
    "    \n",
    "    # ridge\n",
    "    fitridge = cv_optimize_ridge(xtrainsimple, ytrainsimple, n_folds=8)\n",
    "    alpharidge = fitridge.best_params_['alpha']\n",
    "    clfridge = Ridge(alpha=alpharidge).fit(xtrainsimple,ytrainsimple)\n",
    "    predsRidge = clfridge.predict(xvalidatesimple)\n",
    "    prederrors = []\n",
    "    count = 0\n",
    "    for act in yvalidatesimple:\n",
    "        prederrors.append(float(predsRidge[count] - float(act)))\n",
    "        count = count + 1\n",
    "    ridgemsessimple.append(np.mean(squarelist(prederrors)))\n",
    "    ridgemadssimple.append(np.mean(abslist(prederrors))) \n",
    "    coeffsRidge.append(clfridge)\n",
    "    \n",
    "    # lasso\n",
    "    fitlasso = cv_optimize_lasso(xtrainsimple, ytrainsimple, n_folds=8)\n",
    "    alphalasso = fitlasso.best_params_['alpha']\n",
    "    clflasso = Lasso(alpha=alphalasso).fit(xtrainsimple,ytrainsimple)\n",
    "    predsLasso = clflasso.predict(xvalidatesimple)\n",
    "    prederrors = []\n",
    "    count = 0\n",
    "    for act in yvalidatesimple:\n",
    "        prederrors.append(float(predsLasso[count] - float(act)))\n",
    "        count = count + 1\n",
    "    lassomsessimple.append(np.mean(squarelist(prederrors)))\n",
    "    lassomadssimple.append(np.mean(abslist(prederrors)))  \n",
    "    coeffsLasso.append(clflasso)\n",
    "    \n",
    "    # enet\n",
    "    fitenet = cv_optimize_enet(xtrainsimple, forfitsimple[\"gap\"], n_folds=8)\n",
    "    alphaenet = fitenet.best_params_['alpha']\n",
    "    clfenet = ElasticNet(alpha=alphaenet).fit(xtrainsimple,forfitsimple[\"gap\"])\n",
    "    predsEnet = clfenet.predict(xvalidatesimple)\n",
    "    prederrors = []\n",
    "    count = 0\n",
    "    for act in yvalidatesimple:\n",
    "        prederrors.append(float(predsEnet[count] - float(act)))\n",
    "        count = count + 1\n",
    "    enetmsessimple.append(np.mean(squarelist(prederrors)))\n",
    "    enetmadssimple.append(np.mean(abslist(prederrors)))       \n",
    "    coeffsEnet.append(clfenet)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We ran the three sets of predictors on the following four models, to produce a total of 12 fit models.***\n",
    "\n",
    "- **OLS Regression: this is the simplest, go-to model, and we expect it to perform worse than the others, which might filter out unnecessary data well.**\n",
    "\n",
    "\n",
    "- **Ridge Regression: we used this because it ought to set the coefficients of less valuable predictors to near-zero values, which could produce excellent predictions given a large number of predictors.**\n",
    "\n",
    "\n",
    "- **Lasso Regression: we used this because it ought to set the coefficients of less valuable predictors to zero values, which could produce excellent predictions given a large number of predictors.**\n",
    "\n",
    "\n",
    "- **Elastic Net: we used this for similar reasons to the above.**\n",
    "\n",
    "***Again, we trained and validated each of these on the following three predictor sets:***\n",
    "\n",
    "- **Simple set**\n",
    "\n",
    "- **Intuitive set**\n",
    "\n",
    "- **All set**\n",
    "\n",
    "***The model statements for these three predictors sets are printed above.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predesired_features=copy.deepcopy(newdesired_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forpredsimpleAll = pd.DataFrame(dftrain.gap)\n",
    "for xvar in predesired_features:\n",
    "    forpredsimpleAll[xvar] = dftrain[xvar]\n",
    "ytestsimple,xtestsimple = patsy.dmatrices(formulasimple, data=forpredsimpleAll)\n",
    "\n",
    "\n",
    "# Linear\n",
    "minIndex=olsmsessimple.index(min(olsmsessimple))\n",
    "fit=coeffsLinear[minIndex]\n",
    "predsLinearAll = fit.predict(forpredsimpleAll)\n",
    "\n",
    "\n",
    "# Ridge\n",
    "minIndex=ridgemsessimple.index(min(ridgemsessimple))\n",
    "clfRidge=coeffsRidge[minIndex]\n",
    "predsRidgeAll = clfRidge.predict(xtestsimple)\n",
    "\n",
    "# Lasso\n",
    "minIndex=lassomsessimple.index(min(lassomsessimple))\n",
    "clflasso=coeffsLasso[minIndex]\n",
    "predsLassoAll = clflasso.predict(xtestsimple)\n",
    "\n",
    "# Enet\n",
    "minIndex=enetmsessimple.index(min(enetmsessimple))\n",
    "clfEnet=coeffsEnet[minIndex]\n",
    "predsEnetAll = clfEnet.predict(xtestsimple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Root Avg. MSE Next Week's Price:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>0.09991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.09885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.09906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.09937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                All\n",
       "OLS         0.09991\n",
       "Ridge       0.09885\n",
       "Lasso       0.09906\n",
       "ElasticNet  0.09937"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple = [round(np.mean(olsmadssimpleweek),2), round(np.mean(ridgemadssimpleweek),2), \n",
    "# round(np.mean(lassomadssimpleweek),2), round(np.mean(enetmadssimpleweek),2)]\n",
    "# Intuitive = [round(np.mean(olsmadsintuitiveweek),2), round(np.mean(ridgemadsintuitiveweek),2), \n",
    "# round(np.mean(lassomadsintuitiveweek),2), round(np.mean(enetmadsintuitiveweek),2)]\n",
    "All = [round(np.mean(olsmsessimple),5), round(np.mean(ridgemsessimple),5), round(np.mean(lassomsessimple),5), round(np.mean(enetmsessimple),5)]\n",
    "\n",
    "MSEResultstableweek = pd.DataFrame()\n",
    "# MSEResultstableweek[\"Simple\"] = Simple\n",
    "# MSEResultstableweek[\"Intuitive\"] = Intuitive\n",
    "MSEResultstableweek[\"All\"] = All\n",
    "MSEResultstableweek.index = [\"OLS\",\"Ridge\",\"Lasso\", \"ElasticNet\"]\n",
    "print \"Cross Validation Root Avg. MSE Next Week's Price:\"\n",
    "MSEResultstableweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Results for Different Models of Next Week's Price:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1781ba590>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxgAAAIbCAYAAABonjh+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1023b4990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE = All\n",
    "forplottableweek = pd.DataFrame()\n",
    "forplottableweek[\"Root MSE\"] = MSE\n",
    "indices = [list(MSEResultstableweek.index)]\n",
    "forplottableweek.index = indices\n",
    "digits =  [\"All\",\"All\",\"All\", \"All\"]\n",
    "forplottableweek[\"Digits\"] = digits\n",
    "print \"RMSE Results for Different Models of Next Week's Price:\"\n",
    "sns.barplot(y = \"Root MSE\",x = digits, hue = forplottableweek.index.values, data = forplottableweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dftrain.to_csv(\"train1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftest1['gap']=0\n",
    "predesired_features.append('gap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# newdesired_features.remove('gap')\n",
    "dftest2 = dftest1[predesired_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predsRidgeAll=predsRidgeAll.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errEnet=math.sqrt(sum((predsEnetAll-dftrain['gap'])**2)/lenTrain)\n",
    "errLasso=math.sqrt(sum((predsLassoAll-dftrain['gap'])**2)/lenTrain)\n",
    "errRidge=math.sqrt(sum((predsRidgeAll-dftrain['gap'])**2)/lenTrain)\n",
    "errLinear=math.sqrt(sum((predsLinearAll-dftrain['gap'])**2)/lenTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forpredsimpleAll = pd.DataFrame(dftest2.gap)\n",
    "for xvar in predesired_features:\n",
    "    forpredsimpleAll[xvar] = dftrain[xvar]\n",
    "ytestsimple,xtestsimple = patsy.dmatrices(formulasimple, data=forpredsimpleAll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error=[errLinear,errLasso,errRidge,errEnet]\n",
    "\n",
    "bestmodel=[fit,clflasso,clfRidge,clfEnet][error.index(min(error))]\n",
    "if error.index(min(error))==0:\n",
    "    predsBestModel = bestmodel.predict(dftest2)\n",
    "elif error.index(min(error))==2:\n",
    "    predsBestModel = bestmodel.predict(xtestsimple)\n",
    "    predsBestModel=predsBestModel.ravel()\n",
    "else:\n",
    "    predsBestModel = bestmodel.predict(xtestsimple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.7429361 ,  1.59786198,  1.66510141,  1.73375643,  2.00090825,\n",
       "        2.00731003,  2.40682141,  1.72420758,  2.14364576,  1.85998459,\n",
       "        1.77021043,  2.00090825,  2.3207271 ,  1.99905041,  1.60139688,\n",
       "        2.29712445,  2.0391523 ,  2.13326644,  2.15710887,  1.63006128,\n",
       "        1.72999516,  1.7429361 ,  2.04269479,  2.21358449,  1.74038175,\n",
       "        1.77800229,  2.09544673,  1.60780002,  1.80560598,  1.87248277,\n",
       "        1.77800229,  2.32472814,  1.67821516,  2.25334271,  1.75759886,\n",
       "        2.15710887,  1.63546412,  1.60780002,  2.43134048,  1.70707256,\n",
       "        2.25334271,  1.74260673,  2.15710887,  1.96504471,  1.72420758,\n",
       "        2.17124945,  2.0391523 ,  1.74647859,  2.15710887,  2.25334271,\n",
       "        2.25334271,  2.14884926,  1.75759886,  1.7429361 ,  1.31829443,\n",
       "        2.2010863 ,  2.14884926,  1.59313726,  2.14884926,  1.57440874,\n",
       "        1.57626658,  1.62026217,  1.54969918,  1.98217973,  2.14884926,\n",
       "        2.15710887,  2.18471257,  2.41252668,  1.7429361 ,  2.40682141,\n",
       "        1.75347981,  1.72420758,  2.25702256,  1.82870104,  1.93259309,\n",
       "        1.31829443,  1.59313726,  2.16724841,  2.15710887,  2.45368347,\n",
       "        2.01977219,  1.70786056,  1.75119572,  1.80560598,  1.59313726,\n",
       "        1.75504451,  2.04269479,  1.62546567,  2.51131486,  2.01362564,\n",
       "        2.07550199,  2.18471257,  1.31829443,  1.53097066,  2.00090825,\n",
       "        1.88458597,  1.95561234,  1.89121129,  1.77644463,  2.14629491,\n",
       "        1.89121129,  1.98217973,  2.0391523 ,  2.05257939,  2.14884926,\n",
       "        2.00090825,  1.49858943,  1.60308289,  2.41508102,  2.17645295,\n",
       "        2.29712445,  1.58019632,  2.05257939,  1.59313726,  2.03677157,\n",
       "        1.7429361 ,  2.14884926,  1.42646774,  1.45726361,  2.41508102,\n",
       "        1.7429361 ,  1.68400274,  2.17999544,  2.14884926,  2.11111645,\n",
       "        1.31936488,  1.69045532,  1.63323914,  1.72165323,  2.39215842,\n",
       "        1.77221471,  1.74260673,  2.00916787,  1.70235543,  2.00090825,\n",
       "        1.69763072,  1.7429361 ,  2.13418627,  1.65298388,  1.93687435,\n",
       "        1.60201244,  1.77221471,  1.97962538,  2.00722908,  2.29712445,\n",
       "        2.15710887,  1.51785692,  2.18471257,  2.0391523 ,  2.14884926,\n",
       "        1.59313726,  2.05055511,  1.84742956,  1.7429361 ,  1.69763072,\n",
       "        1.6789022 ,  1.60139688,  1.75759886,  2.12583001,  1.70451821,\n",
       "        1.84025416,  1.97135007,  1.57626658,  1.34756665,  1.92377007,\n",
       "        1.5733395 ,  1.85998459,  2.14884926,  1.62241587,  1.4250643 ,\n",
       "        1.99905041,  1.38302966,  2.25078837,  1.75759886,  1.84742956,\n",
       "        2.05002504,  1.72420758,  2.14629491,  2.41508102,  1.86785786,\n",
       "        2.25334271,  1.80560598,  1.36630155,  2.18471257,  2.10540171,\n",
       "        1.9796703 ,  2.02665411,  1.98217973,  1.99905041,  2.00090825,\n",
       "        1.75119572,  1.98624527,  2.25334271,  2.15710887,  1.9796703 ,\n",
       "        2.28462626,  1.59313726,  2.01301666,  1.7429361 ,  1.98321604,\n",
       "        1.57626658,  1.75119572,  1.57626658,  2.25334271,  1.75119572,\n",
       "        1.64149876,  1.57440874,  1.59313726,  2.12946915,  1.64149876,\n",
       "        2.25702256,  1.99905041,  1.95561234,  2.02016662,  2.40682141,\n",
       "        1.84742956,  1.72995913,  1.2771233 ,  1.63678163,  1.92570314,\n",
       "        1.75119572,  2.04741192,  2.40682141,  1.99905041,  1.71523576,\n",
       "        1.75181128,  2.25334271,  1.72355599,  1.72420758,  2.04269479,\n",
       "        2.17645295,  1.75181128,  1.65419264,  1.82870104,  1.9796703 ,\n",
       "        1.2771233 ,  1.89608543,  1.99905041,  2.0391523 ,  2.15710887,\n",
       "        1.72999516,  1.95561234,  1.59313726,  1.72420758,  1.89608543,\n",
       "        1.75759886,  1.98217973,  1.82870104,  1.74647859,  2.25334271,\n",
       "        2.00090825,  2.14884926,  2.15710887,  2.00090825,  1.63323914,\n",
       "        2.00090825,  2.03491373,  1.7429361 ,  1.82870104,  2.14884926,\n",
       "        2.15710887,  2.13872015,  1.84742956,  2.40426706,  2.14629491,\n",
       "        2.3207271 ,  2.21358449,  1.69694368,  1.63323914,  1.75181128,\n",
       "        1.7429361 ,  1.57626658,  1.57440874,  1.72420758,  2.51131486,\n",
       "        1.7429361 ,  1.7429361 ,  1.53323761,  1.31829443,  2.17645295,\n",
       "        1.75119572,  1.9796703 ,  1.72355599,  1.99570475,  1.65298388,\n",
       "        2.13046053,  1.98438743,  2.15710887,  2.02851195,  2.02497569,\n",
       "        1.16849558,  1.80560598,  1.70235543,  2.13326644,  2.00916787,\n",
       "        1.54969918,  1.71805902,  2.32472814,  2.00090825,  2.02497569,\n",
       "        1.59786198,  2.15710887,  1.57626658,  2.14884926,  2.44013037,\n",
       "        2.10354387,  2.02665411,  1.7429361 ,  2.08667319,  2.17348261,\n",
       "        1.78894282,  1.63323914,  2.00978343,  1.96504471,  2.00731003,\n",
       "        2.16724841,  2.15710887,  1.75119572,  1.72165323,  1.59313726,\n",
       "        1.66510141,  1.75181128,  2.02665411,  2.25702256,  1.75759886,\n",
       "        1.72355599,  1.72420758,  1.55913156,  1.75119572,  1.75181128,\n",
       "        2.28094641,  2.14884926,  2.3207271 ,  1.87248277,  1.87895041,\n",
       "        1.98217973,  1.20859747,  2.14884926,  2.41508102,  1.74647859,\n",
       "        1.72272369,  1.61712375,  1.85998459,  2.40682141,  2.17336833,\n",
       "        1.62241587,  1.83238089,  2.0391523 ,  2.02448931,  1.87248277,\n",
       "        2.40682141,  1.98217973,  2.01145196,  1.94311415,  1.95560287,\n",
       "        2.0391523 ,  1.89121129,  1.90187301,  1.52426006,  1.57440874,\n",
       "        1.7429361 ,  2.14884926,  2.08650074,  1.59313726,  2.14884926,\n",
       "        1.95561234,  1.60139688,  2.0391523 ,  2.07101457,  2.18471257,\n",
       "        1.63678163,  2.14364576,  2.15710887,  2.15710887,  2.03018686,\n",
       "        1.99905041,  1.64198513,  2.1269148 ,  1.99905041,  2.41884229,\n",
       "        2.08770949,  2.14884926,  1.84025416,  1.74647859,  2.10354387,\n",
       "        1.31829443,  2.17999544,  1.99905041,  2.00090825,  1.72999516,\n",
       "        2.15710887,  2.17645295,  1.90008647,  2.0391523 ,  2.03018686,\n",
       "        2.15239175,  2.14884926,  1.9204899 ,  1.59313726,  2.01557101,\n",
       "        2.02497569,  2.16724841,  2.12946915,  1.9796703 ,  2.14884926,\n",
       "        1.77021043,  1.31536734,  2.15710887,  1.32408201,  2.00090825,\n",
       "        2.04741192,  1.95137377,  2.40426706,  1.99264841,  1.65001956,\n",
       "        1.78894282,  2.15710887,  2.3483308 ,  2.04760761,  1.59313726,\n",
       "        1.84742956,  1.89608543,  1.88038802,  1.72420758,  1.72527804,\n",
       "        1.77800229,  2.41508102,  1.7429361 ,  1.7429361 ,  2.17348261,\n",
       "        1.71900408,  1.72165323,  2.13872015,  2.15710887,  2.12946915,\n",
       "        2.3966923 ,  2.41508102,  1.58019632,  2.14884926,  1.99905041,\n",
       "        2.17645295,  1.7429361 ,  2.13418627,  1.85784283,  1.82870104,\n",
       "        1.74660778,  2.15710887,  1.88093808,  1.96504471,  2.04741192,\n",
       "        1.94311415,  1.9796703 ,  1.75759886,  1.72355599,  2.40161791,\n",
       "        1.7429361 ,  1.57626658,  1.72527804,  2.21936075,  2.17348261,\n",
       "        1.57626658,  1.72420758,  2.40682141,  1.75119572,  2.14884926,\n",
       "        2.08667319,  1.7429361 ,  2.40682141,  1.75462851,  1.95137377,\n",
       "        2.11111645,  2.04741192,  1.99905041,  1.57626658,  2.03491373,\n",
       "        1.74864137,  1.36630155,  2.14884926,  2.08667319,  1.74647859,\n",
       "        2.01557101,  1.47447486,  2.1498374 ,  2.16724841,  2.17336833,\n",
       "        2.0025929 ,  2.02763251,  2.00090825,  1.5920744 ,  2.14884926,\n",
       "        2.17348261,  2.10540171,  1.82870104,  1.72355599,  2.01557101,\n",
       "        2.18471257,  2.14884926,  1.99905041,  1.64464196,  1.99905041,\n",
       "        1.82870104,  1.89608543,  2.02851195,  1.21650271,  2.00731003,\n",
       "        1.99905041,  2.11172254,  2.25334271,  1.75347981,  2.17348261,\n",
       "        1.5733395 ,  2.40426706,  1.88226507,  1.6789022 ,  1.96447804,\n",
       "        1.68303645,  2.02665411,  1.7429361 ,  1.31829443,  1.95137377,\n",
       "        2.40682141,  2.3483308 ,  1.61650819,  1.58019632,  2.02000391,\n",
       "        1.72355599,  1.36630155,  2.17336833,  2.14884926,  2.02000391,\n",
       "        1.98217973,  1.63323914,  1.33988983,  1.72999516,  2.1498374 ,\n",
       "        1.70235543,  2.02242134,  1.63943079,  1.71900408,  1.3516857 ,\n",
       "        2.40682141,  1.7429361 ,  1.68303645,  1.4250643 ,  1.89121129,\n",
       "        1.61906253,  2.13418627,  2.15710887,  2.18471257,  1.6055388 ,\n",
       "        1.7429361 ,  2.0391523 ,  1.84742956,  2.44268472,  1.98217973,\n",
       "        2.25702256,  1.7429361 ,  1.33410225,  1.91481395,  1.7429361 ,\n",
       "        1.57626658,  1.99905041,  1.5733395 ,  2.25078837,  1.61409076,\n",
       "        1.72420758,  2.19892151,  1.42278788,  1.77408229,  2.15710887,\n",
       "        2.40315717,  2.15710887,  1.7429361 ,  2.14884926,  1.81654651,\n",
       "        1.31829443,  2.14884926,  1.7429361 ,  2.14619826,  1.60780002,\n",
       "        2.14884926,  1.75119572,  2.12946915,  1.30746477,  1.77644463,\n",
       "        2.14884926,  2.40682141,  2.25334271,  2.17348261,  1.97135007,\n",
       "        1.56543692,  2.28409598,  2.18471257,  1.53675824,  1.84742956,\n",
       "        2.29712445,  2.00090825,  1.9983539 ,  1.65001956,  1.8996666 ,\n",
       "        1.80560598,  2.15710887,  2.51131486,  1.60780002,  1.66084284,\n",
       "        2.00090825,  2.00916787,  2.21358449,  1.69694368,  1.7429361 ,\n",
       "        2.15239175,  1.60201244,  2.04741192,  2.29712445,  1.63323914,\n",
       "        2.04741192,  1.72420758,  1.75759886,  1.31829443,  2.15455453,\n",
       "        2.53636421,  2.01977219,  2.25334271,  1.75759886,  1.7429361 ,\n",
       "        2.03491373,  1.72420758,  1.64838827,  1.31936488,  2.14619826,\n",
       "        2.13418627,  2.25334271,  1.83238089,  2.02000391,  2.13872015,\n",
       "        2.02612383,  1.31829443,  1.93687435,  1.89947091,  2.0391523 ,\n",
       "        2.15710887,  1.7429361 ,  1.94311415,  1.32152766,  1.7429361 ,\n",
       "        2.14884926,  2.00978343,  1.74884093,  1.82870104,  1.72420758,\n",
       "        2.14884926,  1.7429361 ,  1.7429361 ,  1.72420758,  1.31829443,\n",
       "        1.89121129,  2.40682141,  1.57440874,  1.39501173,  1.98217973,\n",
       "        2.05257939,  2.15455453,  2.4344251 ,  2.17999544,  1.72999516,\n",
       "        2.02763251,  2.12946915,  1.72420758,  1.7052033 ,  1.7429361 ,\n",
       "        2.02497569,  1.60387027,  1.54969918,  2.29712445,  1.72165323,\n",
       "        1.91527873,  1.5920744 ,  2.15707284,  1.7429361 ,  1.72420758,\n",
       "        1.72827312,  2.1269148 ,  1.91481395,  1.58205416,  2.02000391,\n",
       "        1.5579588 ,  2.00090825,  1.72420758,  2.02242134,  1.87206291,\n",
       "        1.36630155,  2.15707284,  1.9983539 ,  1.47502493,  1.75181128,\n",
       "        2.12946915,  2.0905154 ,  2.13418627,  1.91551045,  2.14884926,\n",
       "        2.03597444,  1.57626658,  2.04741192,  1.7429361 ,  2.14884926,\n",
       "        1.60201244,  1.76133525,  2.18471257,  1.75181128,  1.84742956,\n",
       "        1.7429361 ,  1.91881499,  2.18215822,  2.15710887,  1.69231316,\n",
       "        2.17645295,  1.72999516,  1.42278788,  1.7429361 ,  1.31829443,\n",
       "        2.04741192,  1.98217973,  1.71805902,  1.64004635,  1.74647859,\n",
       "        1.56436194,  2.07550199,  2.25334271,  2.02665411,  1.91527873,\n",
       "        2.33298776,  2.17645295,  1.87248277,  2.02000391,  1.98624527,\n",
       "        2.22184411,  2.08770949,  2.02016662,  1.60201244,  1.85110941,\n",
       "        1.84025416,  1.92377007,  2.06675599,  1.65580714,  2.40682141,\n",
       "        1.72999516,  2.15455453,  2.15710887,  1.49595985,  1.31829443,\n",
       "        1.9983539 ,  1.78894282,  2.25334271,  1.72420758,  1.72999516,\n",
       "        2.14884926,  2.13872015,  2.13326644,  1.75119572,  1.77221471,\n",
       "        1.72735329,  1.72420758,  2.29712445,  1.66510141,  1.82870104,\n",
       "        1.71523576,  1.2065295 ,  1.31936488,  1.85998459,  1.74260673,\n",
       "        2.17645295,  1.57440874,  2.01557101,  2.25078837,  2.14884926,\n",
       "        2.25334271,  1.77800229,  2.02497569,  1.96580503,  1.81985073,\n",
       "        2.40682141,  2.17645295,  2.27159779,  1.82870104,  2.03018686,\n",
       "        1.72420758,  1.7429361 ,  2.00722908,  2.00090825,  1.65298388,\n",
       "        1.77800229,  2.40682141,  1.62241587,  2.18471257,  1.67150455,\n",
       "        1.29644228,  1.65419264,  1.7429361 ,  1.75119572,  2.3207271 ,\n",
       "        1.57626658,  1.7429361 ,  2.25334271,  1.45106912,  2.14884926,\n",
       "        1.66830533,  2.07101457,  1.76756945,  2.15710887,  2.16724841,\n",
       "        2.0391523 ,  2.40682141,  1.7429361 ,  1.72420758,  2.18471257,\n",
       "        1.72420758,  1.97962538,  1.66251775,  2.02000391,  1.2771233 ,\n",
       "        1.31829443,  1.62241587,  1.72420758,  1.72527804,  1.72999516,\n",
       "        1.42278788,  2.40315717,  2.12946915,  2.14875261,  1.90008647,\n",
       "        1.7429361 ,  2.02497569,  1.87248277,  2.2010863 ,  1.99905041,\n",
       "        2.12114891,  2.15710887,  2.15710887,  1.61451062,  1.75759886,\n",
       "        1.75119572,  2.0391523 ,  1.31936488,  2.02665411,  1.7429361 ,\n",
       "        1.80468615,  2.07501561,  2.40682141,  2.14884926,  1.49017227,\n",
       "        2.00978343,  1.7429361 ,  1.72827312,  2.1948521 ,  2.11859457,\n",
       "        2.40682141,  1.67150455,  1.56436194,  1.80560598,  1.7429361 ,\n",
       "        2.40682141,  2.16724841,  1.64318477,  1.58651193,  2.09822631,\n",
       "        1.59313726,  1.61451062,  1.53323761,  1.72420758,  1.71523576,\n",
       "        1.7429361 ,  1.72165323,  1.57440874,  1.71337792,  1.75759886,\n",
       "        1.92377007,  2.20735029,  2.0301966 ,  1.89121129,  1.07646428,\n",
       "        2.14884926,  1.59599271,  1.36630155,  1.62546567,  1.7705398 ,\n",
       "        2.14884926,  1.7429361 ,  1.82614669,  2.02000391,  2.14884926,\n",
       "        2.00916787,  2.12946915,  1.6242737 ,  1.75119572,  1.72827312,\n",
       "        1.98217973,  2.40682141,  2.1498374 ,  2.16724841,  1.59313726,\n",
       "        1.82614669,  2.12946915,  2.15710887,  1.33988983,  2.02000391,\n",
       "        2.15710887,  1.99905041,  2.14884926,  1.72420758,  2.4292216 ,\n",
       "        2.14884926,  1.75759886,  2.15710887,  1.59313726,  2.15710887,\n",
       "        2.17645295,  1.29644228,  1.67462094,  2.10354387,  2.13872015,\n",
       "        1.95561234,  2.02665411,  2.40682141,  2.07501561,  1.74260673,\n",
       "        1.75119572,  1.70235543,  2.41508102,  1.79224704,  2.00090825,\n",
       "        2.13418627,  1.90415201,  2.15710887,  1.95561234,  1.77800229,\n",
       "        1.43434101,  2.51131486,  2.02448931,  1.98796731,  2.04741192,\n",
       "        1.31829443,  1.71805902,  1.72999516,  1.70235543,  1.72420758,\n",
       "        2.10354387,  2.29712445,  1.62241587,  2.25334271,  2.00731003,\n",
       "        2.14884926,  2.1738986 ,  2.02000391,  1.16849558,  2.17348261,\n",
       "        2.18471257,  1.94311415,  2.10284736,  1.42278788,  1.9204899 ,\n",
       "        2.17645295,  1.59313726,  1.75119572,  1.89121129,  1.84742956,\n",
       "        2.25702256,  2.04741192,  1.75181128,  1.53869132,  1.72420758,\n",
       "        1.72420758,  1.7429361 ,  1.98217973,  1.7429361 ,  2.15710887,\n",
       "        2.00090825,  2.17645295,  2.03491373,  2.13418627,  2.5049366 ,\n",
       "        1.99905041,  2.02665411,  2.18471257,  1.2771233 ,  1.59313726,\n",
       "        1.82870104,  2.07501561,  2.41508102,  1.31829443,  1.78253616,\n",
       "        2.14884926,  2.23495399,  1.89608543,  1.64390086,  1.9796703 ,\n",
       "        2.10354387,  1.84487521,  2.02763251,  1.57626658,  1.75119572])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# error=[newdftrain['errLinear'].mean(),newdftrain['errLasso'].mean(),newdftrain['errRidge'].mean(),newdftrain['errEnet'].mean()]\n",
    "predsBestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to submit best1.csv\n",
    "write_to_file(\"best1.csv\", predsBestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
